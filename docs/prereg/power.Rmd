---
title: "WET power"
author: "Elad Zlotnick"
date: "`r Sys.Date()`"
output: html_document
bibliography: "`r normalizePath('~/projects/zettlr/zotero.json')`"
csl: "`r normalizePath('~/projects/zettlr/apa.csl')`"
---

```{r setup, include=FALSE}
library(tidyverse)
library(faux)
library(lme4)
knitr::opts_chunk$set(echo = TRUE)
```

# Power analyses for WET

We would like to find the effect size of WET.
We will do this by comparing pre-post symptom level on the OASIS [@normanDevelopmentValidationOverall2006], between a treatment group and a control group.
The treatment group will write about their core fears, the control group will write about a neutral suject.
We will analyze the results using a multilevel variant of ANCOVA, defined as follows:


$$  y_{it} \sim N(\mu_{it}, \sigma_\epsilon) $$

$$ \mu_{it} = \beta_0 + \beta_1 \text{time}_{it} + {\color{red}{\beta_2}} \text{tx}_{it}\text{time}_{it} + u_{0i} $$

$$u_{0i} \sim \mathcal N(0, \sigma_0)$$

The effect size is $\beta_2$, marked in red above.

We fit this in lmer as follows:
```r
lmer( y ~ 1 + time + tx:time + (1 | id), data = d) 
```

## Simulation

Now we want to simulat our data.
We do this by sampling from a multinormal distribution.
We define `rho` ($\rho$) as the correlation between pre and post data.
This is important because it stands for individual differences.
We set it to $.6$ by default, because that is the standard effect we commonly see.

We define `tau` ($\tau$) as the effect size - we simply add it to the post score of the treatment group.
The effect size is defined as the mean diffence between groups divided by the pooled $SD$ pre treatment [see @feingoldEffectSizesGrowthmodeling2009].


```{r}
sim_data <- function(seed = 1, n = 100, tau = 1, rho = .5, missing = .2) {
  
  # population values
  m <- 0
  s <- 1
  
  # simulate and save
  set.seed(seed)
  
  rnorm_multi(
    n = n,
    mu = c(m, m),
    sd = c(s, s), 
    r = rho, 
    varnames = list("pre", "post")
  ) %>% 
    mutate(tx = rep(0:1, each = n / 2)) %>% 
    mutate(post = ifelse(tx == 1, post + tau, post)) %>%
    mutate(id = 1:n()) %>% 
    mutate(post = ifelse(rbinom(n = n(), size = 1, prob = missing) == 1, NA, post)) %>% 
    pivot_longer(pre:post, names_to = "wave", values_to = "y") %>% 
    mutate(time = ifelse(wave == "pre", 0, 1))
  
}
```

## outcomes

```{r}

# 246 -> tau 0.3
# 148 -> tau 0.4 [.16]
# 98 -> tau 0.5

n = 150
out = sapply(1:1000, function(x){
  d = sim_data(seed = x, n = n, tau = 0.6, missing = 0.6)
  m = lmer( y ~ 1 + time + tx:time + (1 | id), data = d) %>% summary %>% .$coefficients
  m[3,]
})

z_critical <- qt(p = .95, df = n)
mean(out[3,] > z_critical)
mean(out[2,])
```
